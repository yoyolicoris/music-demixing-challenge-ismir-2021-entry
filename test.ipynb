{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd05a140685ab34bba06285d598f885c3cc7ba27ac59a54bc998545a1833638ae27",
   "display_name": "Python 3.7.10 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from musdb import DB\n",
    "import museval\n",
    "import argparse\n",
    "import soundfile as sf\n",
    "from tqdm import trange\n",
    "import os\n",
    "from ignite.handlers import Checkpoint\n",
    "\n",
    "from model import X_UMX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config.json'\n",
    "checkpoint_path = 'saved/x-umx_checkpoint_362400.pt'\n",
    "estimate_path = 'estimates/'\n",
    "chunk_dur = 30\n",
    "sr = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "X_UMX(\n",
       "  (affine1): Sequential(\n",
       "    (0): Conv1d(11896, 2048, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
       "    (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Tanh()\n",
       "  )\n",
       "  (bass_lstm): LSTM(512, 256, num_layers=3, dropout=0.4, bidirectional=True)\n",
       "  (drums_lstm): LSTM(512, 256, num_layers=3, dropout=0.4, bidirectional=True)\n",
       "  (vocals_lstm): LSTM(512, 256, num_layers=3, dropout=0.4, bidirectional=True)\n",
       "  (others_lstm): LSTM(512, 256, num_layers=3, dropout=0.4, bidirectional=True)\n",
       "  (affine2): Sequential(\n",
       "    (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(2048, 16392, kernel_size=(1,), stride=(1,), groups=4, bias=False)\n",
       "    (4): BatchNorm1d(16392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "config = json.load(open(config_path))\n",
    "\n",
    "db = DB(config['root'], is_wav=True, subsets='test')\n",
    "\n",
    "max_bins = int(config[\"bandwidth\"] / sr * config['nfft']) + 1\n",
    "model = X_UMX(config['nfft'], config['nhop'], config['hidden_size'], max_bins, 2, 3)\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "to_load = {\n",
    "    'model': model\n",
    "}\n",
    "Checkpoint.load_objects(to_load=to_load, checkpoint=checkpoint)\n",
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AM Contra - Heart Peripheral\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.49it/s]\n",
      "Al James - Schoolboy Facination\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.35it/s]\n",
      "Angels In Amplifiers - I'm Alright\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "#results = museval.EvalStore(frames_agg='median', tracks_agg='median')\n",
    "chunk_size = int(chunk_dur * sr)\n",
    "for track in db[:3]:\n",
    "    print(track.name)\n",
    "    os.makedirs(os.path.join(estimate_path, track.name), exist_ok=True)\n",
    "    audio = track.audio\n",
    "    if (audio.shape[0] % chunk_size) == 0:\n",
    "        nchunks = (audio.shape[0] // chunk_size)\n",
    "    else:\n",
    "        nchunks = (audio.shape[0] // chunk_size) + 1\n",
    "    outputs = []\n",
    "    for chunk_idx in trange(nchunks):\n",
    "        cur_chunk = audio[chunk_idx * chunk_size: min((chunk_idx + 1) * chunk_size, audio.shape[0]),:]\n",
    "        x = torch.from_numpy(cur_chunk).float().t().unsqueeze(0).cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            X = model.t2f(x)\n",
    "            Xmag = X.abs()\n",
    "            pred_mask = model(Xmag)\n",
    "            xpred = model.f2t(pred_mask * X.unsqueeze(1), length=x.shape[-1]).squeeze().cpu().numpy()\n",
    "        \n",
    "        outputs.append(xpred)\n",
    "    xpred = np.concatenate(outputs, 2)\n",
    "    for i, s in enumerate(['drums', 'bass', 'other', 'vocals']):\n",
    "        sf.write(\n",
    "            os.path.join(estimate_path, track.name, s + '.wav'),\n",
    "            xpred[i].T,\n",
    "            sr\n",
    "        )\n",
    "\n",
    "    #estimates = {\n",
    "    #    'drums': xpred[0].T,\n",
    "    #    'bass': xpred[1].T,\n",
    "    #    'other': xpred[2].T, \n",
    "    #    'vocals': xpred[3].T\n",
    "    #}\n",
    "    #score = museval.eval_mus_track(track, estimates)\n",
    "    #print(score)\n",
    "    #results.add_track(score)"
   ]
  }
 ]
}